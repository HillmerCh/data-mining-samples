{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvsGSzP7GHZ8"
   },
   "source": [
    "## 1. Load data\n",
    "- pandas is a convenient package to represent and process tabular data: https://pandas.pydata.org/docs/user_guide/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ahfijjv0GHZ_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "29mHdC8LGHaA"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # this package is for matrix computation\n",
    "import pandas as pd  # this package is for data formating and processing\n",
    "\n",
    "# load data from data file\n",
    "#train_df = pd.read_csv('/kaggle/input/heart-attack/train.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "prediction_X_df = pd.read_csv('data/test_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie8MllbdGHaB"
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOvLSZG8MWLX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "for i, col in enumerate(['Age', 'Sex', 'ChestPainType', 'RestingBP','Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope']):\n",
    "    plt.figure(i)\n",
    "    sns.catplot(x=col, y='HeartDisease', data=train_df, kind='point', aspect=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRT8mxk3RubB"
   },
   "outputs": [],
   "source": [
    "train_df.pivot_table('HeartDisease',index='Sex', columns='Age', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0gxrrHBGHaB"
   },
   "source": [
    "## 2. Data processing\n",
    "- Categorical feature -> numerical feature\n",
    "- Feature scaling: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "ukQXiDNTGHaC",
    "outputId": "d21ec30e-dfe4-435e-d1db-965490795965"
   },
   "outputs": [],
   "source": [
    "# this function is to convert categorical feature to numerical (one-hot representation)\n",
    "def convert_categorical_to_numerical(df):\n",
    "    new_df = df.copy()  # so operations on new_df will not influence df\n",
    "\n",
    "    # check get_dummies doc: https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html for more info\n",
    "    sex = pd.get_dummies(new_df['Sex'], prefix='sex', dtype=float) # convert Sex to integer values\n",
    "    chest = pd.get_dummies(new_df['ChestPainType'], prefix='chest', dtype=float) # convert ChestPainType to float values\n",
    "    # YOUR TASK: convert other categorical features\n",
    "    restingECG = pd.get_dummies(new_df['RestingECG'], prefix='restingECG', dtype=float) # convert RestingECG to float values\n",
    "    exerciseAngina = pd.get_dummies(new_df['ExerciseAngina'], prefix='exerciseAngina', dtype=float) # convert ExerciseAngina to float values\n",
    "    sT_Slope = pd.get_dummies(new_df['ST_Slope'], prefix='sT_Slope', dtype=float) # convert ST_Slope to float values\n",
    "\n",
    "    # drop categorical features with their numerical values\n",
    "    # YOUR TASK: drop other categorical features\n",
    "    new_df.drop(['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # create new dataframe with only numerical values\n",
    "    # YOUR TASK: concatenate with other converted features\n",
    "    new_df = pd.concat([new_df, sex, chest, restingECG, exerciseAngina, sT_Slope], axis=1)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "# convert features for training and testing data\n",
    "my_train_df = convert_categorical_to_numerical(train_df)\n",
    "my_prediction_X_df = convert_categorical_to_numerical(prediction_X_df)\n",
    "\n",
    "my_train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dv1HutrtGHaD"
   },
   "outputs": [],
   "source": [
    "# You may apply feature proceccing tricks mentioned in class\n",
    "# e.g., feature normalization/standardization etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEqhT9LqsXlQ"
   },
   "outputs": [],
   "source": [
    "#temp to remove some features\n",
    "\n",
    "my_prediction_X_df = my_prediction_X_df.drop([\"sex_M\", \"exerciseAngina_N\", ], axis=1)\n",
    "my_train_df = my_train_df.drop([\"sex_M\", \"exerciseAngina_N\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Cfutacusy6X",
    "outputId": "9138fdcb-6f1f-44af-f050-14adf3cc1374"
   },
   "outputs": [],
   "source": [
    "my_prediction_X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzg4XX9NQ_vR"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "my_prediction_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_prediction_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOwTky-NHkG4"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wzolDM1NJoR"
   },
   "outputs": [],
   "source": [
    "#ITERATION 2\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def select_kbest_clf(data_frame, target, k=2):\n",
    "    \"\"\"\n",
    "    Selecting K-Best features for classification\n",
    "    :param data_frame: A pandas dataFrame with the training data\n",
    "    :param target: target variable name in DataFrame\n",
    "    :param k: desired number of features from the data\n",
    "    :returns feature_scores: scores for each feature in the data as\n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "    feat_selector = SelectKBest(f_classif, k=k)\n",
    "    _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n",
    "\n",
    "    feat_scores = pd.DataFrame()\n",
    "    feat_scores[\"F Score\"] = feat_selector.scores_\n",
    "    feat_scores[\"P Value\"] = feat_selector.pvalues_\n",
    "    feat_scores[\"Support\"] = feat_selector.get_support()\n",
    "    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n",
    "\n",
    "    return feat_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFY3t6MpPRRS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxnDBNRM8udH",
    "outputId": "3708d3e6-e948-4468-a2c6-6f04c3675e0d"
   },
   "outputs": [],
   "source": [
    "\n",
    "n_feat = 21\n",
    "kbest_feat = select_kbest_clf(my_train_df, \"HeartDisease\", k=n_feat)\n",
    "kbest_feat_sorted = kbest_feat.sort_values([\"F Score\", \"P Value\"], ascending=[False, False], ignore_index=True)\n",
    "\n",
    "kbest_feat_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_features = []\n",
    "for it in range(0, (n_feat-1)):\n",
    "  best_features.append(kbest_feat_sorted['Attribute'][it])\n",
    "\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h_HsoIH5Rb3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#features = my_train_df.drop([\"HeartDisease\", \"PatientID\"], axis=1)#Iteration 1\n",
    "features = my_train_df[best_features] #Iteration 2\n",
    "labels = my_train_df['HeartDisease']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "#prediction_X = my_prediction_X_df.drop([\"PatientID\"], axis=1)\n",
    "prediction_X = my_prediction_X_df[best_features]#Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sg87lB_8Iq2Q"
   },
   "outputs": [],
   "source": [
    "#NO Iteration 2\n",
    "#from sklearn.feature_selection import SelectKBest, chi2\n",
    "#train_X_new = SelectKBest(chi2, k=20).fit_transform(train_X, train_y)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "select_k_best_classifier = SelectKBest(f_classif, k=10).fit_transform(train_X, train_y)\n",
    "\n",
    "\n",
    "print(train_X.shape,  select_k_best_classifier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIED4Y7LJKED"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2Ndy5PINgNx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Smba5w4MnfJ"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOAssthP9SEm"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# prepare features and labels for training/testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yRgKKVy9Sc4",
    "outputId": "967c11df-a31f-44ab-93fc-6726d7965591"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#model = RandomForestClassifier(n_estimators=240, max_depth=8, random_state=5) # 0.96875 0.972644376899696 - 0.8333333333333334 0.8620689655172413\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9947916666666666 0.9953775038520801 - 0.8333333333333334 0.8620689655172413\n",
    "#model = KNeighborsClassifier(n_neighbors=11) # 0.8958333333333334 0.9093655589123866 - 0.7986111111111112 0.8304093567251463\n",
    "#model = LogisticRegression(C=0.1) #0.8802083333333334 0.8949771689497718 .8263888888888888 0.8571428571428572\n",
    "#model = SVC(kernel='rbf', C=1, random_state=5) #0.9131944444444444 0.9242424242424242 0.8333333333333334 0.8636363636363635\n",
    "#model = SVC(kernel='linear', C=21, random_state=5) #0.8871527777777778 0.9016641452344931 0.8333333333333334 0.8620689655172413\n",
    "\n",
    "#ITERATION 2\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.8055555555555556 0.8444444444444446 - 0.8055555555555556 0.8444444444444446\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=3, random_state=5) # 0.8472222222222222 0.8682634730538922 - 0.8055555555555556 0.8444444444444446\n",
    "\n",
    "#ITERATION 3 10s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=3, random_state=5) # 0.859375 0.8785607196401799 - 0.7986111111111112 0.8379888268156424\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=5, random_state=5) # 0.8958333333333334 0.9096385542168673 - 0.8125 0.8439306358381502\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.8958333333333334 0.9096385542168673 - 0.8263888888888888 0.8554913294797688\n",
    "#model = LogisticRegression(C=0.1) #0.8611111111111112 0.8776758409785933 - 0.8125 0.8457142857142856\n",
    "\n",
    "#ITERATION 4 7s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9097222222222222 0.9204892966360857 - 0.8194444444444444 0.853932584269663\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=5, random_state=5) # 0.8784722222222222 0.8955223880597015 - 0.8194444444444444 0.853932584269663\n",
    "\n",
    "#ITERATION 4 15s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9930555555555556 0.9938461538461539 - 0.8333333333333334 0.8620689655172413\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=5, random_state=5) # 0.9079861111111112 0.9200603318250377 - 0.8472222222222222 0.875\n",
    "\n",
    "\n",
    "#ITERATION 5 13s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9913194444444444 0.9922720247295208 - 0.8333333333333334 0.8604651162790696\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=5, random_state=5) # 0.9079861111111112 0.9200603318250377 - 0.8472222222222222 0.875\n",
    "\n",
    "#ITERATION 6 17s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9965277777777778 0.9969135802469136 - 0.8402777777777778 0.8700564971751412\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=7, random_state=5) # 0.9513888888888888 0.9569230769230769 - 0.8333333333333334 0.8636363636363635\n",
    "\n",
    "\n",
    "#ITERATION 6 12s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9913194444444444 0.9922958397534669 - 0.8125 0.8439306358381502\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=6, random_state=5) # 0.9184027777777778 0.928462709284627 - 0.8125 0.8421052631578947\n",
    "\n",
    "#ITERATION 7 9s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9913194444444444 0.9922958397534669 - 0.8125 0.8439306358381502\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=5, random_state=5) # 0.890625 0.9044006069802731 - 0.7986111111111112 0.8361581920903955\n",
    "\n",
    "#ITERATION 11 9s k\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9861111111111112 0.9876923076923076 - 0.8402777777777778 0.8654970760233917\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=5, random_state=5) # 0.8958333333333334 0.9096385542168673 - 0.8263888888888888 0.8571428571428572\n",
    "#model = RandomForestClassifier(n_estimators=210, max_depth=5, random_state=5) # 0.8975694444444444 0.9112781954887218 - 0.8194444444444444 0.8505747126436781\n",
    "\n",
    "\n",
    "#ITERATION 11 10s k No Male No N\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9913194444444444 0.9922958397534669 - 0.8125 0.8439306358381502\n",
    "#model = RandomForestClassifier(n_estimators=210, max_depth=5, random_state=5) # 0.9913194444444444 0.9922958397534669 - 0.9045138888888888 0.9167927382753404\n",
    "\n",
    "\n",
    "#ITERATION 12 19s k No Male No N\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9861111111111112 0.9876923076923076 - 0.8263888888888888 0.8571428571428572\n",
    "#model = RandomForestClassifier(n_estimators=210, max_depth=5, random_state=5) # 0.8993055555555556 0.9129129129129129 - 0.8055555555555556 0.8409090909090909\n",
    "\n",
    "#ITERATION 13 all  No Male No N\n",
    "#model = RandomForestClassifier(n_estimators=220, max_depth=10, random_state=5) # 0.9982638888888888 0.9984591679506933 - 0.8402777777777778 0.8715083798882682\n",
    "#model = RandomForestClassifier(n_estimators=210, max_depth=7, random_state=5) # 0.9565972222222222 0.9618320610687022 - 0.8472222222222222 0.8764044943820224 **\n",
    "\n",
    "#ITERATION 14 13  No Male No N\n",
    "#model = RandomForestClassifier(n_estimators=190, max_depth=5, random_state=5) # 0.9097222222222222 0.9214501510574018 - 0.8263888888888888 0.8587570621468928\n",
    "#model = RandomForestClassifier(n_estimators=160, max_depth=6, random_state=5) # 0.9461805555555556 0.9528158295281582 - 0.8263888888888888 0.8571428571428572\n",
    "\n",
    "#ITERATION 15 11  No Male No N\n",
    "#model = RandomForestClassifier(n_estimators=190, max_depth=6, random_state=5) # 0.9322916666666666 0.9404580152671755 - 0.8402777777777778 0.8685714285714287\n",
    "#model = RandomForestClassifier(n_estimators=210, max_depth=5, random_state=5) # 0.9131944444444444 0.9244712990936556 - 0.7916666666666666 0.8295454545454546\n",
    "\n",
    "#  8-- 10 -- 11 --12 -15\n",
    "\n",
    "#FINAL 20\n",
    "model = RandomForestClassifier(n_estimators=210, max_depth=7, random_state=5) # 0.953125 0.9586523736600305 - 0.8472222222222222 0.8764044943820224 **\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "# evaluate accuracy/f1 score on training data\n",
    "train_y_pred = model.predict(train_X)\n",
    "print(accuracy_score(train_y, train_y_pred) , f1_score(train_y, train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZvrL-U_AQil",
    "outputId": "bc2a0e89-dced-48ba-d227-fb421b5d7755"
   },
   "outputs": [],
   "source": [
    "# evaluate accuracy/f1 score on test data (20%)\n",
    "test_y_pred = model.predict(test_X)\n",
    "print(accuracy_score(test_y, test_y_pred), f1_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb0eMTkdAQ-1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhQMytIJGCzS",
    "outputId": "13732861-feb7-4788-9d1a-ea8af52acff3"
   },
   "outputs": [],
   "source": [
    "base_model_rf = RandomForestClassifier(random_state=5)\n",
    "parameters = {\n",
    "    'n_estimators': [150, 160, 180, 190, 210, 220 ],\n",
    "    'max_depth': [5,6, 7, 10]\n",
    "}\n",
    "\n",
    "cv_rf = GridSearchCV(base_model_rf, parameters, cv=5)\n",
    "cv_rf.fit(train_X, train_y)\n",
    "\n",
    "print(cv_rf.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(cv_rf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "TNBnjxFAGDYU",
    "outputId": "5941c249-22a9-40aa-ea21-ab20532f6506"
   },
   "outputs": [],
   "source": [
    "cv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs7o0yqqGXTH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b9kki8PEyPv"
   },
   "outputs": [],
   "source": [
    "svc = SVC(random_state=5)\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf', 'gausian'],\n",
    "    'C': [0.1, 0.9,1,2, 10, 11, 13, 21, 25]\n",
    "}\n",
    "\n",
    "model_svc = GridSearchCV(svc, parameters, cv=5,  scoring='f1')\n",
    "\n",
    "model_svc.fit(train_X, train_y)\n",
    "print(model_svc.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(model_svc.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TA55gPnaFJBr"
   },
   "outputs": [],
   "source": [
    "model_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2imJqveTDQ2L"
   },
   "source": [
    "4. Make predictions and format them into required submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "9nf9pkYjCns2",
    "outputId": "de48783c-f457-4240-b963-d5d69729136c"
   },
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "\n",
    "#original test_y_pred = model.predict(test_X)\n",
    "#prediction_X = my_prediction_X_df.drop([\"PatientID\"], axis=1)\n",
    "prediction_y_pred = model.predict(prediction_X)\n",
    "\n",
    "# prepare the prediction file to submit on Kaggle\n",
    "submission_df = pd.DataFrame({\n",
    "    'PatientID': my_prediction_X_df['PatientID'],\n",
    "    'HeartDisease': prediction_y_pred\n",
    "    }\n",
    ")\n",
    "submission_df.to_csv(\"y_predict_rf-all-feat-v23.csv\", index=False)\n",
    "submission_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aB9t2K2CoFT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4u17tj-9S0u"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_model_rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [220, 240, 250, 255, 270],\n",
    "    'max_depth': [3,5,6, 7, 8, 10]\n",
    "}\n",
    "\n",
    "#RandomForestClassifier(max_depth=7, n_estimators=250)\n",
    "\n",
    "#'n_estimators': [5, 50, 250],\n",
    "#'max_depth': [2, 4, 8, 16, 32, None]\n",
    "\n",
    "cv_rf = GridSearchCV(base_model_rf, parameters, cv=5)\n",
    "cv_rf.fit(train_X, train_y)\n",
    "\n",
    "print(cv_rf.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(cv_rf.cv_results_['mean_test_score']) # average validation performance for different hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfHsUn-I-FAC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEJA-Oe8652H"
   },
   "outputs": [],
   "source": [
    "for dataset in [y_train, y_test]:\n",
    "    print(round(len(dataset)/len(labels), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8520y9Y7B7V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqVMUg1OGHaE"
   },
   "outputs": [],
   "source": [
    "# Iteration 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2yaBXE3GHaE"
   },
   "outputs": [],
   "source": [
    "# Iteration 2\n",
    "mean_train = my_train_df['Cholesterol'].mean()\n",
    "my_train_df['Cholesterol'].replace(0, mean_train, inplace=True)\n",
    "\n",
    "mean_test = my_test_X_df['Cholesterol'].mean()\n",
    "my_test_X_df['Cholesterol'].replace(0, mean_test, inplace=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtJG_37YGHaE"
   },
   "outputs": [],
   "source": [
    "# Iteration 3\n",
    "my_train_df['Cholesterol_valid'] = np.where(my_train_df['Cholesterol'].eq(0), 1, 0)\n",
    "my_test_X_df['Cholesterol_valid'] = np.where(my_test_X_df['Cholesterol'], 1, 0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqrS8rxaGHaF"
   },
   "outputs": [],
   "source": [
    "##Next cell are test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iya8PTaDGHaF"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "#my_train_df['Cholesterol_valid'] = my_train_df[['Cholesterol']].eq(0).any(axis=1)\n",
    "\n",
    "#my_train_df['eq'] = np.where(df['eq'], 'Y', 'N')\n",
    "\n",
    "#my_train_df['Cholesterol_valid'] = np.where(my_train_df['Cholesterol'].eq(0), 1, 0)\n",
    "#my_test_X_df['Cholesterol_valid'] = np.where(my_test_X_df['Cholesterol'], 1, 0)\n",
    "\n",
    "\n",
    "#mean_train = my_train_df['Cholesterol'].mean()\n",
    "#my_train_df['Cholesterol'] = np.where(my_train_df['Cholesterol'].eq(0), mean_train, my_train_df['Cholesterol'])\n",
    "\n",
    "#mean_test = my_test_X_df['Cholesterol'].mean()\n",
    "#my_test_X_df['Cholesterol'] = np.where(my_test_X_df['Cholesterol'].eq(0), mean_test, my_test_X_df['Cholesterol'])\n",
    "\n",
    "\n",
    "mean_train = my_train_df['Cholesterol'].mean()\n",
    "my_train_df['Cholesterol'].replace(0, mean_train, inplace=True)\n",
    "\n",
    "mean_test = my_test_X_df['Cholesterol'].mean()\n",
    "my_test_X_df['Cholesterol'].replace(0, mean_test, inplace=True)\n",
    "\n",
    "#my_train_df['Oldpeak'] = my_train_df['Oldpeak'].abs()\n",
    "#my_test_X_df['Oldpeak'] = my_test_X_df['Oldpeak'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tifDty0dGHaG"
   },
   "outputs": [],
   "source": [
    "my_train_df.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k4PpK47GHaG"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Calculating the Rolling Z-Score\n",
    "#window_size = 20\n",
    "#train_X['rolling_zscore'] = (train_X['Cholesterol'] - train_X['Cholesterol'].rolling(window_size).mean()) / train_X['Cholesterol'].rolling(window_size).std()\n",
    "\n",
    "#Identifying Outliers\n",
    "\n",
    "#train_X['outlier'] = (train_X['rolling_zscore'] > 3) | (train_X['rolling_zscore'] < -3)\n",
    "\n",
    "#import scipy.stats as stats\n",
    "#my_train_df['cholesterol_zscore'] = stats.zscore(my_train_df['Cholesterol'])\n",
    "#my_train_df.head()\n",
    "\n",
    "##TODO my_test_X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdOxGD9PGHaH"
   },
   "outputs": [],
   "source": [
    "# Dropping  Hillmer\n",
    "\n",
    "# Cholesterol Many zero values\n",
    "\n",
    "#my_train_df.groupby('Cholesterol')['Cholesterol'].count()\n",
    "#my_train_df.groupby('HeartDisease')['HeartDisease'].count()\n",
    "#my_train_df.groupby('Oldpeak')['Oldpeak'].count()\n",
    "#my_train_df.groupby('RestingBP')['RestingBP'].count() #80 to 200\n",
    "#my_train_df.groupby('MaxHR')['MaxHR'].count() #\n",
    "#my_train_df.groupby('Age')['Age'].count()\n",
    "#my_train_df['MaxHR']> 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bml5e9PzGHaI"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(my_train_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s56M29FdGHaI"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm = MinMaxScaler().fit(my_train_df)\n",
    "my_train_df_norm = norm.transform(my_train_df)\n",
    "my_train_df = my_train_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLbjjDXbGHaI"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler().fit(my_train_df)\n",
    "my_train_df_scaled = scale.transform(my_train_df)\n",
    "my_train_df_scaled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npEd0OFAGHaJ"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GroaIOsGHaJ"
   },
   "outputs": [],
   "source": [
    "#NO\n",
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(my_train_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "\n",
    "test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = scaler.fit_transform(test_X_df[['Age','RestingBP', 'Cholesterol', 'MaxHR','Oldpeak']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYTTqgVyGHaK"
   },
   "outputs": [],
   "source": [
    "#TEMP\n",
    "#my_train_df.groupby('FastingBS')['FastingBS'].count() #0 & 1\n",
    "#my_train_df.groupby('HeartDisease')['HeartDisease'].count() #0 & 1\n",
    "#my_train_df.groupby('Oldpeak')['Oldpeak'].count() #-2 TO 6.2\n",
    "#my_train_df[['Oldpeak']] = scaler.fit_transform(my_train_df[['Oldpeak']])\n",
    "\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#my_train_df[['Cholesterol']] = scaler.fit_transform(my_train_df[['Cholesterol']])\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#my_train_df[['MaxHR']] = scaler.fit_transform(my_train_df[['MaxHR']])\n",
    "\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#my_train_df['RestingBP_scal'] = scaler.fit_transform(my_train_df[['RestingBP']])\n",
    "\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "#norm = Normalizer()\n",
    "#my_train_df['RestingBP_norm'] = norm.fit_transform(my_train_df[['RestingBP']])\n",
    "\n",
    "#my_train_df['RestingBP_ori'] = my_train_df['RestingBP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdhqelHYGHaK"
   },
   "outputs": [],
   "source": [
    "my_train_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsOJy9jpGHaK"
   },
   "source": [
    "## 3. Create classifier and fit the data\n",
    "- sklearn is a convenient package for ML: https://scikit-learn.org/stable/\n",
    "- you are encouraged to try any ML models: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "- you are encouraged to try model selection methods: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFInlZlpGHaL"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# prepare features and labels for training/testing\n",
    "\n",
    "train_X = my_train_df.drop([\"HeartDisease\", \"PatientID\"], axis=1)\n",
    "train_y = my_train_df[\"HeartDisease\"]\n",
    "test_X = my_test_X_df.drop([\"PatientID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJ3rs4UUGHaL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEkK4ooqGHaM"
   },
   "outputs": [],
   "source": [
    "#model = RandomForestClassifier(max_depth=7, n_estimators=255) # 0.9347222222222222 0.943577430972389\n",
    "#model = LogisticRegression(C=0.1) # 0.8763888888888889 0.8934131736526946\n",
    "model = KNeighborsClassifier(n_neighbors=11) # 0.8861111111111111 0.9023809523809524\n",
    "model.fit(train_X, train_y)\n",
    "# evaluate accuracy/f1 score on training data\n",
    "train_y_pred = model.predict(train_X)\n",
    "print(accuracy_score(train_y, train_y_pred) , f1_score(train_y, train_y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Twy2zosGHaM"
   },
   "outputs": [],
   "source": [
    "#NEXT CELL ARE TESTs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ6_lEGHGHaN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define and fit your model, with manually set hyperparameter\n",
    "# e.g., here is an example of KNN classifier, and you may tune the hyperparameter \"n_neighbors\"\n",
    "#model = KNeighborsClassifier(n_neighbors=11, weights='uniform', algorithm='auto')\n",
    "#m1\n",
    "#model = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "#m2\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#model = LogisticRegression(C=0.01)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=32)\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=7) # Sub 0.86666 0.9375 0.9458483754512635\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=8) # Sub 0.8599 0.9611111111111111 0.9663461538461539\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=10) # Sub 0.83582 0.9833333333333333 0.9854368932038836\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=10) # Sub 0.82587 0.9875 0.9890909090909091\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=240, max_depth=8)# Sub 0.xxxx 0.9375 0.9458483754512635\n",
    "\n",
    "\n",
    "#NO SUBMITTED model = RandomForestClassifier(max_depth=8, n_estimators=250) #w Oldpeak abs 0.9611111111111111 0.9663461538461539\n",
    "\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#model = GaussianNB(var_smoothing= 0.1) # 0.65\n",
    "\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#model = DecisionTreeClassifier(random_state=0, max_depth=3) 0.22\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#model = SVC(kernel='rbf', C=1)\n",
    "\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate accuracy/f1 score on training data\n",
    "train_y_pred = model.predict(train_X)\n",
    "print(accuracy_score(train_y, train_y_pred))\n",
    "print(f1_score(train_y, train_y_pred))\n",
    "\n",
    "#model = KNeighborsClassifier(n_neighbors=11) 0.66\n",
    "#0.8861111111111111\n",
    "#0.9021479713603817\n",
    "\n",
    "#model = LogisticRegression() 0.02\n",
    "#0.8722222222222222\n",
    "#0.8896882494004797\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators=250, max_depth=32) 0.81\n",
    "# 1.0\n",
    "# 1.0\n",
    "\n",
    "#model = SVC(kernel='rbf', C=1)\n",
    "#0.9069444444444444\n",
    "#0.919952210274791\n",
    "\n",
    "\n",
    "#model = GaussianNB() 0.65306\n",
    "#0.8569444444444444\n",
    "#0.8751515151515152\n",
    "\n",
    "#model = GaussianNB(var_smoothing= 0.1873817422860384)\n",
    "#0.8666666666666667\n",
    "#0.8829268292682927\n",
    "\n",
    "#model = GaussianNB(var_smoothing= 0.1)\n",
    "#0.8708333333333333\n",
    "#0.8872727272727274\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m6yKvZtGHaN"
   },
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_rS41VJGHaO"
   },
   "outputs": [],
   "source": [
    "#HC model selection: hyperparameter tuning\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_model_rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [220, 240, 250, 255, 270],\n",
    "    'max_depth': [3,5,6, 7, 8, 10]\n",
    "}\n",
    "\n",
    "#RandomForestClassifier(max_depth=7, n_estimators=250)\n",
    "\n",
    "#'n_estimators': [5, 50, 250],\n",
    "#'max_depth': [2, 4, 8, 16, 32, None]\n",
    "\n",
    "cv_rf = GridSearchCV(base_model_rf, parameters, cv=5)\n",
    "cv_rf.fit(train_X, train_y)\n",
    "\n",
    "print(cv_rf.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(cv_rf.cv_results_['mean_test_score']) # average validation performance for different hyperparameter values\n",
    "\n",
    "#[0.81666667 0.84444444 0.84861111 0.84166667 0.85972222 0.86944444\n",
    "# 0.85277778 0.86666667 0.87083333 0.82777778 0.86805556 0.87222222\n",
    "# 0.84166667 0.85694444 0.87222222 0.83194444 0.86944444 0.86805556]\n",
    "#MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to0yiw99GHaP"
   },
   "outputs": [],
   "source": [
    "# HC\n",
    "cv_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5mU7m-hGHaP"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 0.9,1,2, 10]\n",
    "}\n",
    "\n",
    "model_svc = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "model_svc.fit(train_X, train_y)\n",
    "print(model_svc.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(model_svc.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E07shETEGHaR"
   },
   "outputs": [],
   "source": [
    "model_svc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTiOVW7RGHaR"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "base_model_dt = DecisionTreeClassifier()\n",
    "hyperpara_grid = {'max_depth':[4,5,6,7,8,9,10]} # candidate values for the hyperparameter to try\n",
    "dt = KNeighborsClassifier()\n",
    "#HC clf = GridSearchCV(base_model, hyperpara_grid, cv=5) # 5-fold cross validation\n",
    "dt = GridSearchCV(base_model_dt, hyperpara_grid, cv=5, scoring='f1') # 5-fold cross validation\n",
    "dt.fit(train_X, train_y)\n",
    "print(dt.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(dt.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAFR7d0lGHaS"
   },
   "outputs": [],
   "source": [
    "# model selection: hyperparameter tuning\n",
    "hyperpara_grid = {'n_neighbors':[3, 5, 8, 10, 11, 13, 15]} # candidate values for the hyperparameter to try\n",
    "\n",
    "#hyperpara_grid = {'n_neighbors':[11]} # candidate values for the hyperparameter to try\n",
    "base_model = KNeighborsClassifier()\n",
    "#HC clf = GridSearchCV(base_model, hyperpara_grid, cv=5) # 5-fold cross validation\n",
    "clf = GridSearchCV(base_model, hyperpara_grid, cv=5, scoring='f1') # 5-fold cross validation\n",
    "clf.fit(train_X, train_y)\n",
    "print(clf.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(clf.cv_results_['mean_test_score']) # average validation performance for different hyperparameter values\n",
    "\n",
    "#[0.73402355 0.74541386 0.72588925 0.72236912 0.74330666 0.739037  ]\n",
    "# w/o                [0.71085231 0.71198864 0.70331137 0.72746104 0.74635724 0.73829504]\n",
    "#cholesterol z-score [0.7156104  0.7097872  0.70730967 0.72430988 0.74725948 0.73686977]\n",
    "#MinMaxScaler() [0.72640991 0.74269164 0.73082418 0.73898587 0.76037838 0.754347  ]\n",
    "#StandardScaler 'Age','RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak'\n",
    "#0.86661442 0.88982141 0.89073001 0.89803115 0.89585915 0.89646112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXIXkxVXGHaT"
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOKfQKHsGHaV"
   },
   "outputs": [],
   "source": [
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "cv.fit(tr_features, tr_labels.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6hy_maOGHaV"
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pf6mavU8GHaW"
   },
   "outputs": [],
   "source": [
    "#HC model selection: hyperparameter tuning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model_lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "cv_lr = GridSearchCV(base_model_lr, parameters, cv=5)\n",
    "cv_lr.fit(train_X, train_y)\n",
    "\n",
    "print(cv_lr.cv_results_.keys()) # all results for 5-fold cross validation\n",
    "print(cv_lr.cv_results_['mean_test_score']) # average validation performance for different hyperparameter values\n",
    "\n",
    "#[0.74305556 0.82916667 0.85972222 0.86388889 0.85972222 0.8625 0.85694444]\n",
    "#MinMaxScaler() [0.71944444 0.82083333 0.86111111 0.85972222 0.85694444 0.85694444 0.85972222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGOgocctGHaX"
   },
   "outputs": [],
   "source": [
    "cv_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re-3q2BvGHaX"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "parameters = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier,\n",
    "                 param_grid=parameters,\n",
    "                 cv=5,   # use any cross validation technique\n",
    "                 verbose=1,\n",
    "                 scoring='accuracy')\n",
    "gs_NB.fit(train_X, train_y)\n",
    "\n",
    "gs_NB.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpgZ2uF-GHaY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrGoLk1xGHaY"
   },
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgBDwOmVGHaY"
   },
   "source": [
    "## 4. Make predictions and format them into required submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCd8G8c1GHaZ"
   },
   "outputs": [],
   "source": [
    "# make predictions on test data\n",
    "\n",
    "#original test_y_pred = model.predict(test_X)\n",
    "test_y_pred = model.predict(test_X)\n",
    "\n",
    "# prepare the prediction file to submit on Kaggle\n",
    "submission_df = pd.DataFrame({\n",
    "    'PatientID': my_test_X_df['PatientID'],\n",
    "    'HeartDisease': test_y_pred\n",
    "    }\n",
    ")\n",
    "submission_df.to_csv(\"y_predict.csv\", index=False)\n",
    "submission_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZST_RI5lGHaZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
