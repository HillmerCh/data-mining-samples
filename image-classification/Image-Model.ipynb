{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Refer to the Pytorch tutorial for more details: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ],
   "metadata": {
    "id": "8IC6GQx9pKsB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:12:08.757889Z",
     "iopub.execute_input": "2023-10-17T04:12:08.759377Z",
     "iopub.status.idle": "2023-10-17T04:12:08.765256Z",
     "shell.execute_reply.started": "2023-10-17T04:12:08.759329Z",
     "shell.execute_reply": "2023-10-17T04:12:08.763755Z"
    },
    "trusted": true,
    "id": "6rRHewsCpKsH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data\n",
    "\n",
    "The training data is a standard image benchmark from torchvision.\n",
    "\n",
    "The test data is downloaded from the Kaggle competition which is a subset of the benchmark test set."
   ],
   "metadata": {
    "id": "TBBwRCR3pKsJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# load and transfor training data from standard source\n",
    "mean = (0.5, 0.5, 0.5) # 0.485, 0.456, 0.406\n",
    "std = (0.5, 0.5, 0.5)  #  0.229, 0.224, 0.255\n",
    "#transforms.resize(224, 224)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=mean, std=std)]) # normalize image to [-1, 1]\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# dataloader for batch training (mini-batch gradient descent)\n",
    "batch_size=8\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# 10 classes in total\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:12:12.627896Z",
     "iopub.execute_input": "2023-10-17T04:12:12.628552Z",
     "iopub.status.idle": "2023-10-17T04:12:13.628669Z",
     "shell.execute_reply.started": "2023-10-17T04:12:12.628508Z",
     "shell.execute_reply": "2023-10-17T04:12:13.627037Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFZhSU4apKsJ",
    "outputId": "d12e3f8e-b495-4f2e-b1ab-d412be39efbc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# load test data (note that the data has been transformed already)\n",
    "test_images = torch.load('./data/test_image.pt')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:12:28.434335Z",
     "iopub.execute_input": "2023-10-17T04:12:28.434686Z",
     "iopub.status.idle": "2023-10-17T04:12:28.961544Z",
     "shell.execute_reply.started": "2023-10-17T04:12:28.434658Z",
     "shell.execute_reply": "2023-10-17T04:12:28.959689Z"
    },
    "trusted": true,
    "id": "DRaUEx25pKsK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cBMH9Ph8auYg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Take a look at your image data"
   ],
   "metadata": {
    "id": "X5UitF6qpKsK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get a random batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape, labels)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:12:34.542523Z",
     "iopub.execute_input": "2023-10-17T04:12:34.542937Z",
     "iopub.status.idle": "2023-10-17T04:12:35.035378Z",
     "shell.execute_reply.started": "2023-10-17T04:12:34.542907Z",
     "shell.execute_reply": "2023-10-17T04:12:35.034427Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "bjPT9L5TpKsK",
    "outputId": "a0aa57d1-42e7-432c-f13a-ec35c6925192"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build a simple CNN model\n",
    "\n",
    "Your tasks:\n",
    "* Check the Pytorch document about Conv2d, MaxPool2d and Linear to understand the meaning of arguments\n",
    "* Tune the model hyperparameters"
   ],
   "metadata": {
    "id": "D5SkWWgspKsL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# YOUR TASK: set the hyperparameters of CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.conv1 = nn.Conv2d(3, 2, 5) # input channel=3, num of filter=2, size of filter=5*5\n",
    "        \"\"\"[1,  1000] loss: 2.307\n",
    "        [1,  2000] loss: 2.302\n",
    "        [1,  3000] loss: 2.291\n",
    "        [1,  4000] loss: 2.226\n",
    "        [1,  5000] loss: 2.121\n",
    "        [1,  6000] loss: 2.072\"\"\"\n",
    "        #self.conv1 = nn.Conv2d(3, 2, 3) # input channel=3, num of filter=2, size of filter=3*3\n",
    "        \"\"\"[1,  1000] loss: 2.306\n",
    "        [1,  2000] loss: 2.304\n",
    "        [1,  3000] loss: 2.303\n",
    "        [1,  4000] loss: 2.302\n",
    "        [1,  5000] loss: 2.302\n",
    "        [1,  6000] loss: 2.300\"\"\"\n",
    "        #self.conv1 = nn.Conv2d(3, 2, 4) # input channel=3, num of filter=2, size of filter=4\n",
    "        \"\"\" [1,  1000] loss: 2.305\n",
    "        [1,  2000] loss: 2.304\n",
    "        [1,  3000] loss: 2.303\n",
    "        [1,  4000] loss: 2.303\n",
    "        [1,  5000] loss: 2.303\n",
    "        [1,  6000] loss: 2.303 \"\"\"\n",
    "\n",
    "        #self.pool = nn.MaxPool2d(2, 2)\n",
    "        #self.conv2 = nn.Conv2d(2, 2, 5)\n",
    "        #self.fc1 = nn.Linear(2 * 5 * 5, 64)\n",
    "        #self.fc2 = nn.Linear(64, 32)\n",
    "        #self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)#\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:18:01.453496Z",
     "iopub.execute_input": "2023-10-17T04:18:01.453898Z",
     "iopub.status.idle": "2023-10-17T04:18:01.464061Z",
     "shell.execute_reply.started": "2023-10-17T04:18:01.453867Z",
     "shell.execute_reply": "2023-10-17T04:18:01.462981Z"
    },
    "trusted": true,
    "id": "4tA0n4Q4pKsM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.parameters"
   ],
   "metadata": {
    "id": "QztoXRwAcJAK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up optimization method\n",
    "\n",
    "You tasks:\n",
    "* Check the Pytorch document about SGD to understand the optimization method\n",
    "* Tune the optimization hyperparameters"
   ],
   "metadata": {
    "id": "-F9SS9Q2pKsM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# YOUR TASK: observe the convergence speed and tune the learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:18:05.469473Z",
     "iopub.execute_input": "2023-10-17T04:18:05.469882Z",
     "iopub.status.idle": "2023-10-17T04:18:05.476068Z",
     "shell.execute_reply.started": "2023-10-17T04:18:05.469850Z",
     "shell.execute_reply": "2023-10-17T04:18:05.474770Z"
    },
    "trusted": true,
    "id": "PHADiYBLpKsM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train CNN on training data via mini-batch SGD\n",
    "\n",
    "Your tasks:\n",
    "* Check how loss changes\n",
    "* Based on its convergence, tune the optimizer and epoch number\n",
    "* Try adjust the model to see if the low can futher decrease to lower value"
   ],
   "metadata": {
    "id": "-0zvoEt3pKsN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# YOUR TASK: observe the loss change and set the right epoch number\n",
    "total_epoch = 10\n",
    "for epoch in range(total_epoch):  # loop over the dataset 'total_epoch' times\n",
    "    running_loss = 0.0\n",
    "    accumulated_running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): # for each batch of data\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs) # forward pass\n",
    "        loss = criterion(outputs, labels) # calc loss\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # one step gradient descent\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        accumulated_running_loss += loss.item()\n",
    "\n",
    "        if i % 1000 == 999:    # print average loss every 1000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print(f'[Accumulated => {epoch + 1}, {i + 1:5d}] loss: {accumulated_running_loss/i:.3f}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:18:07.592093Z",
     "iopub.execute_input": "2023-10-17T04:18:07.592641Z",
     "iopub.status.idle": "2023-10-17T04:18:46.977453Z",
     "shell.execute_reply.started": "2023-10-17T04:18:07.592600Z",
     "shell.execute_reply": "2023-10-17T04:18:46.975208Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjUpZNQ4pKsN",
    "outputId": "b256444e-99d9-40af-b225-b2a702e5150b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#HC to try lr(s)\n",
    "import torch.optim as optim\n",
    "\n",
    "# YOUR TASK: observe the convergence speed and tune the learning rate\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
    "#for lr_ in (0.003, 0.002, 0.001, 0.0009, 0.0007):\n",
    "for lr_ in (0.0007, 0.0005, 0.0003, 0.0001):\n",
    "  print(f'lr= {lr_}')\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr_, momentum=0.9)\n",
    "\n",
    "  # YOUR TASK: observe the loss change and set the right epoch number\n",
    "  total_epoch = 1\n",
    "  for epoch in range(total_epoch):  # loop over the dataset 'total_epoch' times\n",
    "      running_loss = 0.0\n",
    "      for i, data in enumerate(trainloader, 0): # for each batch of data\n",
    "          # get the inputs; data is a list of [inputs, labels]\n",
    "          inputs, labels = data\n",
    "\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          # forward + backward + optimize\n",
    "          outputs = model(inputs) # forward pass\n",
    "          loss = criterion(outputs, labels) # calc loss\n",
    "          loss.backward() # back propagation\n",
    "          optimizer.step() # one step gradient descent\n",
    "\n",
    "          # print statistics\n",
    "\n",
    "\n",
    "          running_loss += loss.item()\n",
    "          if i % 1000 == 999:    # print average loss every 1000 mini-batches\n",
    "              print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "              running_loss = 0.0\n",
    "\n",
    "  print(\"------------------------------------\")\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "id": "oSVaWZw5Twvr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make prediction on test images"
   ],
   "metadata": {
    "id": "1Vwsk2PZpKsO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# since now we're testing (not training), we set no_grad to NOT calculate the gradients\n",
    "with torch.no_grad():\n",
    "    # calculate outputs by running images through the network\n",
    "    outputs = model(test_images)\n",
    "    # the class with the highest probability is what we choose as prediction\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predicted = np.array([classes[i] for i in predicted])\n",
    "\n",
    "print(predicted)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(test_images[:32]))\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['label'] = predicted\n",
    "submission.to_csv(\"submission_tr-10.csv\", index=True, index_label='id')\n",
    "submission.head(32)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-17T04:17:14.033150Z",
     "iopub.execute_input": "2023-10-17T04:17:14.033546Z",
     "iopub.status.idle": "2023-10-17T04:17:14.719369Z",
     "shell.execute_reply.started": "2023-10-17T04:17:14.033519Z",
     "shell.execute_reply": "2023-10-17T04:17:14.718207Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iLL-_X6ZpKsP",
    "outputId": "e8b73a7d-b0f3-46d6-e5cc-2c6cf894cd45"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on test images: {100 * correct // total} %')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh5NI0STCxH3",
    "outputId": "497cc597-92b2-48d3-bef5-c3707cb41183"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
